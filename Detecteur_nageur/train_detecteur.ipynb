{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw\n",
    "from imgaug import augmenters as iaa\n",
    "from imgaug.augmentables.segmaps import SegmentationMapOnImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ROOT_DIR variable to the root directory of the Mask_RCNN git repo\n",
    "ROOT_DIR = './'\n",
    "assert os.path.exists(ROOT_DIR), 'ROOT_DIR does not exist. Did you forget to read the instructions above? ;)'\n",
    "\n",
    "# Import mrcnn libraries\n",
    "sys.path.append(ROOT_DIR) \n",
    "from mrcnn.config import Config\n",
    "import mrcnn.utils as utils\n",
    "from mrcnn import visualize\n",
    "import mrcnn.model as modellib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NageursConfig(Config):\n",
    "    \"\"\"Configuration pour un entrainement fait sur un nageur.\n",
    "    Model ispiré de l'original mais adapté à mon GPU\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"nageur\"\n",
    "\n",
    "    # Batch size = GPU*Img (mieux si élevé mais dépend de la mémoire disponible)\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # Nombres de Classes\n",
    "    NUM_CLASSES = 1 + 1  # background + 1 (nageur)\n",
    "    #ATTENTION : Le background est généré automatiquement, si dans le fichier JSON des annotations il existe une classe background,\n",
    "    #pensez à la supprimer. Sinon vous aurez une erreur.\n",
    "\n",
    "    # Shap\n",
    "    IMAGE_MIN_DIM = 512\n",
    "    IMAGE_MAX_DIM = 512\n",
    "\n",
    "    #Depend de la mémoire, si peu de mémoire, bcps de step.\n",
    "    STEPS_PER_EPOCH = 1000\n",
    "\n",
    "    VALIDATION_STEPS = 5\n",
    "    \n",
    "    # choix du backbone, peut être modifié si on ajoute un autre backbone dans le fichier model.py\n",
    "    BACKBONE = 'resnet50'\n",
    "    #paramètre du RPN\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)\n",
    "    TRAIN_ROIS_PER_IMAGE = 32\n",
    "    MAX_GT_INSTANCES = 50 \n",
    "    POST_NMS_ROIS_INFERENCE = 500 \n",
    "    POST_NMS_ROIS_TRAINING = 1000 \n",
    "    \n",
    "config = NageursConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoLikeDataset(utils.Dataset):\n",
    "    \"\"\" Generates a COCO-like dataset, i.e. an image dataset annotated in the style of the COCO dataset.\n",
    "        See http://cocodataset.org/#home for more information.\n",
    "    \"\"\"\n",
    "    def load_data(self, annotation_json, images_dir):\n",
    "        \"\"\" Load the coco-like dataset from json\n",
    "        Args:\n",
    "            annotation_json: The path to the coco annotations json file\n",
    "            images_dir: The directory holding the images referred to by the json file\n",
    "        \"\"\"\n",
    "        # Load json from file\n",
    "        json_file = open(annotation_json)\n",
    "        coco_json = json.load(json_file)\n",
    "        json_file.close()\n",
    "        \n",
    "        # Add the class names using the base method from utils.Dataset\n",
    "        source_name = \"coco_like\"\n",
    "        for category in coco_json['categories']:\n",
    "            class_id = category['id']\n",
    "            class_name = category['name']\n",
    "            #if class_id < 1:\n",
    "            #    print('Error: Class id for \"{}\" cannot be less than one. (0 is reserved for the background)'.format(class_name))\n",
    "            #    return\n",
    "            \n",
    "            self.add_class(source_name, class_id, class_name)\n",
    "        \n",
    "        # Get all annotations\n",
    "        annotations = {}\n",
    "        for annotation in coco_json['annotations']:\n",
    "            image_id = annotation['image_id']\n",
    "            if image_id not in annotations:\n",
    "                annotations[image_id] = []\n",
    "            annotations[image_id].append(annotation)\n",
    "        \n",
    "        # Get all images and add them to the dataset\n",
    "        seen_images = {}\n",
    "        for image in coco_json['images']:\n",
    "            image_id = image['id']\n",
    "            print (image_id)\n",
    "            if image_id in seen_images:\n",
    "                print(\"Warning: Skipping duplicate image id: {}\".format(image))\n",
    "            else:\n",
    "                seen_images[image_id] = image\n",
    "                try:\n",
    "                    image_file_name = image['file_name']\n",
    "                    print (image_file_name)\n",
    "                    image_width = image['width']\n",
    "                    image_height = image['height']\n",
    "                except KeyError as key:\n",
    "                    print(\"Warning: Skipping image (id: {}) with missing key: {}\".format(image_id, key))\n",
    "                \n",
    "                image_path = os.path.abspath(os.path.join(images_dir, image_file_name))\n",
    "                image_annotations = annotations[image_id]\n",
    "                \n",
    "                # Add the image using the base method from utils.Dataset\n",
    "                self.add_image(\n",
    "                    source=source_name,\n",
    "                    image_id=image_id,\n",
    "                    path=image_path,\n",
    "                    width=image_width,\n",
    "                    height=image_height,\n",
    "                    annotations=image_annotations\n",
    "                )\n",
    "                \n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\" Load instance masks for the given image.\n",
    "        MaskRCNN expects masks in the form of a bitmap [height, width, instances].\n",
    "        Args:\n",
    "            image_id: The id of the image to load masks for\n",
    "        Returns:\n",
    "            masks: A bool array of shape [height, width, instance count] with\n",
    "                one mask per instance.\n",
    "            class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        image_info = self.image_info[image_id]\n",
    "        annotations = image_info['annotations']\n",
    "        instance_masks = []\n",
    "        class_ids = []\n",
    "        \n",
    "        for annotation in annotations:\n",
    "            class_id = annotation['category_id']\n",
    "            mask = Image.new('1', (image_info['width'], image_info['height']))\n",
    "            mask_draw = ImageDraw.ImageDraw(mask, '1')\n",
    "            for segmentation in annotation['segmentation']:\n",
    "                mask_draw.polygon(segmentation, fill=1)\n",
    "                bool_array = np.array(mask) > 0\n",
    "                instance_masks.append(bool_array)\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "        mask = np.dstack(instance_masks)\n",
    "        class_ids = np.array(class_ids, dtype=np.int32)\n",
    "        \n",
    "        return mask, class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#En entrée : path vers le fichier d'annotation, path vers le dossier contenant les images.\n",
    "'''dataset_train = CocoLikeDataset()\n",
    "dataset_train.load_data(ROOT_DIR + '/datasets/nageur/train/coco_annotations.json', ROOT_DIR + '/datasets/nageur/train/images')\n",
    "dataset_train.prepare()\n",
    "'''\n",
    "dataset_train = CocoLikeDataset()\n",
    "dataset_train.load_data(ROOT_DIR + '/datasets/nageur/val/coco_annotations.json', ROOT_DIR + '/datasets/nageur/val/images')\n",
    "dataset_train.prepare()\n",
    "\n",
    "dataset_val = CocoLikeDataset()\n",
    "dataset_val.load_data(ROOT_DIR + '/datasets/nageur/val/coco_annotations.json', ROOT_DIR + '/datasets/nageur/val/images')\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_train\n",
    "for i in range (5):\n",
    "    image = dataset.load_image(i)\n",
    "    mask, class_ids = dataset.load_mask(i)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choix du début de l'entrainement pour le fine tuning\n",
    "init_with = \"coco\"  #  coco or last\n",
    "\n",
    "if init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last(), by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train head Layers\n",
    "# Les autres branches sont figées pendant l'entrainement\n",
    "\n",
    "start_train = time.time()\n",
    "model.train(dataset_train,\n",
    "            dataset_val,            \n",
    "            learning_rate=0.0001, \n",
    "            epochs=15, \n",
    "            layers='heads',\n",
    "            augmentation = iaa.Sometimes(2/3,iaa.OneOf([iaa.Flipud(1)])))#augmentation miroire\n",
    "end_train = time.time()\n",
    "minutes = round((end_train - start_train) / 60, 2)\n",
    "print(f'Training took {minutes} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tuning sur tout le réseau (avec un learning rate plus faible, on est la pour affiner seulement)\n",
    "\n",
    "start_train = time.time()\n",
    "model.train(dataset_train,\n",
    "            dataset_val, \n",
    "            learning_rate=0.0001,\n",
    "            epochs=30, \n",
    "            layers=\"all\",\n",
    "            augmentation = iaa.Sometimes(1/2,iaa.OneOf([iaa.Flipud(1)])))#augmentation miroire\n",
    "end_train = time.time()\n",
    "minutes = round((end_train - start_train) / 60, 2)\n",
    "print(f'Training took {minutes} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:psat]",
   "language": "python",
   "name": "conda-env-psat-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
